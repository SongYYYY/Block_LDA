{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt \n",
    "import random \n",
    "import networkx as nx \n",
    "import itertools \n",
    "import pickle \n",
    "import sklearn \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Cora_enrich/links.txt') as links:\n",
    "    with open('data/Cora_enrich/idxs.txt') as idxs:\n",
    "        with open('data/Cora_enrich/adjlist.txt','a') as adj:\n",
    "            for line in links:\n",
    "                idx=idxs.readline()\n",
    "                adj.write('%s %s\\n'%(idx.strip(),line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.read_adjlist('data/Cora_enrich/adjlist.txt',nodetype=int,create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=np.loadtxt('data/Cora_enrich/idxs.txt',dtype=np.int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_dict={n:i for i,n in enumerate(idxs)}\n",
    "edges=[(idx_dict[s],idx_dict[r]) for s,r in G.edges]\n",
    "G_idx=nx.DiGraph()\n",
    "G_idx.add_edges_from(edges) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_adjlist(G_idx,'data/Cora_enrich/idx_adjlist.txt') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[]\n",
    "with open('data/Cora_enrich/texts.txt') as f:\n",
    "    for line in f:\n",
    "        texts.append(line.strip())\n",
    "labels=[]\n",
    "with open('data/Cora_enrich/labels.txt') as f:\n",
    "    for line in f:\n",
    "        labels.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids={}\n",
    "for i,l in enumerate(labels):\n",
    "    if l in class_ids:\n",
    "        class_ids[l].append(i)\n",
    "    else:\n",
    "        class_ids[l]=[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_frequency(texts,class_name=None,class_ids=None,range=None,method='absolute'):\n",
    "    vectorizer=CountVectorizer(stop_words='english')\n",
    "    if class_name!=None:\n",
    "        texts_class=vectorizer.fit_transform([texts[i] for i in class_ids[class_name]]).toarray()\n",
    "    else:\n",
    "        texts_class=vectorizer.fit_transform(texts).toarray()\n",
    "    if range==None:\n",
    "        range=(0,20)\n",
    "    if method=='absolute':\n",
    "        token_counts=texts_class.sum(axis=0)\n",
    "    elif method=='df':\n",
    "        token_counts=(texts_class>0).sum(axis=0)\n",
    "    sorted_idx=np.argsort(-token_counts)[range[0]:range[1]]\n",
    "    sorted_counts=[token_counts[i] for i in sorted_idx]\n",
    "    sorted_tokens=[vectorizer.get_feature_names()[i] for i in sorted_idx]\n",
    "    return list(zip(sorted_counts,sorted_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_default=sklearn.feature_extraction.text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 25793)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_max = CountVectorizer(stop_words='english',max_df=0.75)\n",
    "X = vectorizer_max.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 25789)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gener', 'problem', 'result', 'use'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_max.stop_words_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_min = CountVectorizer(stop_words='english',min_df=0.005)\n",
    "X = vectorizer_min.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 3890)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'winograd',\n",
       " 'ski',\n",
       " 'weed',\n",
       " 'movi',\n",
       " 'fskbann',\n",
       " 'mangea',\n",
       " 'lyon',\n",
       " 'spoke',\n",
       " 'kci',\n",
       " 'monodi',\n",
       " 'persimmon',\n",
       " 'rigoutso',\n",
       " 'federhen',\n",
       " 'wjh',\n",
       " 'exponent',\n",
       " 'clidean',\n",
       " 'cantor',\n",
       " 'immunolog',\n",
       " 'discord',\n",
       " 'idi',\n",
       " 'howl',\n",
       " 'cern',\n",
       " 'competi',\n",
       " 'rflv',\n",
       " 'plural',\n",
       " 'predistort',\n",
       " 'consideredand',\n",
       " 'subcategor',\n",
       " 'preferr',\n",
       " 'recherch',\n",
       " 'symplect',\n",
       " 'trbp',\n",
       " 'ffjd',\n",
       " 'pedest',\n",
       " 'layman',\n",
       " 'stroock',\n",
       " 'pele',\n",
       " 'geisser',\n",
       " 'sunroof',\n",
       " 'odysseu',\n",
       " 'longlif',\n",
       " 'career',\n",
       " 'quaker',\n",
       " 'sdram',\n",
       " 'rossini',\n",
       " 'sumner',\n",
       " 'costello',\n",
       " 'ltu',\n",
       " 'monocular',\n",
       " 'thatacross',\n",
       " 'wfl',\n",
       " 'muta',\n",
       " 'pola',\n",
       " 'typ',\n",
       " 'lj',\n",
       " 'bewilder',\n",
       " 'sonnet',\n",
       " 'ballestero',\n",
       " 'bollerslev',\n",
       " 'paulokat',\n",
       " 'exacli',\n",
       " 'hgp',\n",
       " 'evinc',\n",
       " 'tmc',\n",
       " 'strikingli',\n",
       " 'sounder',\n",
       " 'uq',\n",
       " 'cellagain',\n",
       " 'indecis',\n",
       " 'oval',\n",
       " 'hussam',\n",
       " 'swarm',\n",
       " 'hire',\n",
       " 'ccm',\n",
       " 'oriet',\n",
       " 'sfring',\n",
       " 'fem',\n",
       " 'whang',\n",
       " 'cujo',\n",
       " 'ssn',\n",
       " 'sedgewick',\n",
       " 'evident',\n",
       " 'autocorrelogram',\n",
       " 'pratic',\n",
       " 'suspens',\n",
       " 'schacter',\n",
       " 'harman',\n",
       " 'falk',\n",
       " 'rc',\n",
       " 'smale',\n",
       " 'bayesianli',\n",
       " 'gallardo',\n",
       " 'christchurch',\n",
       " 'naswami',\n",
       " 'microcomput',\n",
       " 'oncolog',\n",
       " 'bian',\n",
       " 'button',\n",
       " 'rewrot',\n",
       " 'furst',\n",
       " 'fhorn',\n",
       " 'willshaw',\n",
       " 'amnes',\n",
       " 'meliora',\n",
       " 'morsel',\n",
       " 'taboo',\n",
       " 'dgraph',\n",
       " 'chaitin',\n",
       " 'addenda',\n",
       " 'katz',\n",
       " 'recon',\n",
       " 'biject',\n",
       " 'woeging',\n",
       " 'chd',\n",
       " 'dicult',\n",
       " 'bolero',\n",
       " 'koob',\n",
       " 'tnm',\n",
       " 'carrol',\n",
       " 'commite',\n",
       " 'dhead',\n",
       " 'eichenbaum',\n",
       " 'antoniak',\n",
       " 'cov',\n",
       " 'lessen',\n",
       " 'maza',\n",
       " 'raga',\n",
       " 'wyrwicka',\n",
       " 'scanlon',\n",
       " 'propose',\n",
       " 'huffman',\n",
       " 'smolka',\n",
       " 'misleadingli',\n",
       " 'basilevski',\n",
       " 'mole',\n",
       " 'mann',\n",
       " 'jje',\n",
       " 'ndl',\n",
       " 'basy',\n",
       " 'porto',\n",
       " 'mona',\n",
       " 'besic',\n",
       " 'uncollect',\n",
       " 'mathl',\n",
       " 'walach',\n",
       " 'triplic',\n",
       " 'boahen',\n",
       " 'lachter',\n",
       " 'raghan',\n",
       " 'ui',\n",
       " 'burkhardt',\n",
       " 'envi',\n",
       " 'rsb',\n",
       " 'ncertainti',\n",
       " 'toin',\n",
       " 'rodieck',\n",
       " 'zimr',\n",
       " 'hairstyl',\n",
       " 'villega',\n",
       " 'sone',\n",
       " 'solveabl',\n",
       " 'extractnth',\n",
       " 'gorg',\n",
       " 'church',\n",
       " 'yue',\n",
       " 'tommi',\n",
       " 'congressmen',\n",
       " 'stryker',\n",
       " 'gulf',\n",
       " 'helg',\n",
       " 'senn',\n",
       " 'setosa',\n",
       " 'rajamoney',\n",
       " 'gk',\n",
       " 'iceberg',\n",
       " 'thijssen',\n",
       " 'lingl',\n",
       " 'franklin',\n",
       " 'oi',\n",
       " 'marenbach',\n",
       " 'prima',\n",
       " 'mislevi',\n",
       " 'memcof',\n",
       " 'ona',\n",
       " 'feret',\n",
       " 'autour',\n",
       " 'pyrimidin',\n",
       " 'empow',\n",
       " 'fect',\n",
       " 'gx',\n",
       " 'season',\n",
       " 'rhode',\n",
       " 'mtb',\n",
       " 'puskoriu',\n",
       " 'finnegan',\n",
       " 'dnm',\n",
       " 'krauth',\n",
       " 'opn',\n",
       " 'zeigler',\n",
       " 'extinguish',\n",
       " 'subdirectori',\n",
       " 'figlewski',\n",
       " 'subgroup',\n",
       " 'msg',\n",
       " 'prequenti',\n",
       " 'ubpa',\n",
       " 'fanti',\n",
       " 'myer',\n",
       " 'steeg',\n",
       " 'maxfji',\n",
       " 'macquari',\n",
       " 'boddi',\n",
       " 'montfort',\n",
       " 'mcmorri',\n",
       " 'psth',\n",
       " 'hyvrinen',\n",
       " 'treue',\n",
       " 'broca',\n",
       " 'shr',\n",
       " 'warren',\n",
       " 'contin',\n",
       " 'maspar',\n",
       " 'habl',\n",
       " 'serif',\n",
       " 'onlb',\n",
       " 'sitton',\n",
       " 'vidual',\n",
       " 'hsieh',\n",
       " 'parsytec',\n",
       " 'webb',\n",
       " 'beef',\n",
       " 'hendrix',\n",
       " 'trevor',\n",
       " 'accomod',\n",
       " 'jen',\n",
       " 'orsay',\n",
       " 'heartili',\n",
       " 'memb',\n",
       " 'pti',\n",
       " 'submiss',\n",
       " 'god',\n",
       " 'inflat',\n",
       " 'azuma',\n",
       " 'mpg',\n",
       " 'uler',\n",
       " 'ssian',\n",
       " 'getti',\n",
       " 'teiresia',\n",
       " 'mathematik',\n",
       " 'usd',\n",
       " 'elementwis',\n",
       " 'aspir',\n",
       " 'rapn',\n",
       " 'shi',\n",
       " 'procyk',\n",
       " 'pronzato',\n",
       " 'pace',\n",
       " 'senesc',\n",
       " 'hoffman',\n",
       " 'hydrant',\n",
       " 'chandra',\n",
       " 'feelder',\n",
       " 'aloud',\n",
       " 'biometr',\n",
       " 'silvest',\n",
       " 'bever',\n",
       " 'weigel',\n",
       " 'wjd',\n",
       " 'fiesler',\n",
       " 'flog',\n",
       " 'shrubberi',\n",
       " 'mesur',\n",
       " 'dodwel',\n",
       " 'heger',\n",
       " 'redevelop',\n",
       " 'nstanc',\n",
       " 'oni',\n",
       " 'sizabl',\n",
       " 'chroma',\n",
       " 'kathryn',\n",
       " 'adrian',\n",
       " 'knd',\n",
       " 'wilbur',\n",
       " 'feld',\n",
       " 'equalis',\n",
       " 'slatteri',\n",
       " 'illicit',\n",
       " 'awerbuch',\n",
       " 'gomori',\n",
       " 'vite',\n",
       " 'mantain',\n",
       " 'brainstructur',\n",
       " 'flick',\n",
       " 'kazouri',\n",
       " 'harandi',\n",
       " 'sidestep',\n",
       " 'bergner',\n",
       " 'xxiii',\n",
       " 'naher',\n",
       " 'rosenfeld',\n",
       " 'icon',\n",
       " 'misconverg',\n",
       " 'qsnn',\n",
       " 'equin',\n",
       " 'ebola',\n",
       " 'pascali',\n",
       " 'polychronopoulu',\n",
       " 'existait',\n",
       " 'blob',\n",
       " 'maladapt',\n",
       " 'regler',\n",
       " 'numopt',\n",
       " 'broomhea',\n",
       " 'kuck',\n",
       " 'emr',\n",
       " 'ellipt',\n",
       " 'sietsma',\n",
       " 'neocort',\n",
       " 'pfeffer',\n",
       " 'rumulhart',\n",
       " 'fpra',\n",
       " 'peephol',\n",
       " 'maron',\n",
       " 'rlearn',\n",
       " 'pasti',\n",
       " 'misnom',\n",
       " 'astronomi',\n",
       " 'lqankatlvclisdfypgav',\n",
       " 'subchain',\n",
       " 'maunsel',\n",
       " 'shastri',\n",
       " 'pidgin',\n",
       " 'venn',\n",
       " 'verhheg',\n",
       " 'schomburg',\n",
       " 'bonn',\n",
       " 'kleinfeld',\n",
       " 'kurt',\n",
       " 'salk',\n",
       " 'colmerau',\n",
       " 'schaeffer',\n",
       " 'consi',\n",
       " 'tistrategi',\n",
       " 'visnet',\n",
       " 'flightless',\n",
       " 'northrop',\n",
       " 'xing',\n",
       " 'obj',\n",
       " 'corn',\n",
       " 'stl',\n",
       " 'betterfor',\n",
       " 'forese',\n",
       " 'epsp',\n",
       " 'decimat',\n",
       " 'ffffi',\n",
       " 'sunspot',\n",
       " 'sytem',\n",
       " 'compressor',\n",
       " 'hoon',\n",
       " 'vuori',\n",
       " 'felder',\n",
       " 'western',\n",
       " 'spellman',\n",
       " 'night',\n",
       " 'zjx',\n",
       " 'loglisp',\n",
       " 'vim',\n",
       " 'disproportion',\n",
       " 'coda',\n",
       " 'lagr',\n",
       " 'sham',\n",
       " 'nik',\n",
       " 'haslett',\n",
       " 'blockad',\n",
       " 'vibrat',\n",
       " 'elec',\n",
       " 'imam',\n",
       " 'khepsim',\n",
       " 'overgener',\n",
       " 'nativ',\n",
       " 'pulspropag',\n",
       " 'nishikawa',\n",
       " 'dj',\n",
       " 'vcdimens',\n",
       " 'hale',\n",
       " 'krep',\n",
       " 'sdsu',\n",
       " 'quadratur',\n",
       " 'guigo',\n",
       " 'topolgi',\n",
       " 'chom',\n",
       " 'htk',\n",
       " 'szu',\n",
       " 'hesterberg',\n",
       " 'bathroom',\n",
       " 'cjxj',\n",
       " 'jfhh',\n",
       " 'linial',\n",
       " 'lauzon',\n",
       " 'harvard',\n",
       " 'regressor',\n",
       " 'hetero',\n",
       " 'bdcl',\n",
       " 'falmagn',\n",
       " 'nakano',\n",
       " 'overbeek',\n",
       " 'riedmil',\n",
       " 'devour',\n",
       " 'emphasis',\n",
       " 'hbner',\n",
       " 'mdd',\n",
       " 'conklin',\n",
       " 'flargv',\n",
       " 'anu',\n",
       " 'fuch',\n",
       " 'portant',\n",
       " 'multirespons',\n",
       " 'gpengin',\n",
       " 'auraient',\n",
       " 'illinoi',\n",
       " 'nness',\n",
       " 'orien',\n",
       " 'eck',\n",
       " 'desouza',\n",
       " 'jjw',\n",
       " 'narrowli',\n",
       " 'hawley',\n",
       " 'pesch',\n",
       " 'actress',\n",
       " 'cholinesteras',\n",
       " 'mcardl',\n",
       " 'daytim',\n",
       " 'datahandl',\n",
       " 'collomb',\n",
       " 'stir',\n",
       " 'wake',\n",
       " 'opportunit',\n",
       " 'friedrichshafen',\n",
       " 'ecritur',\n",
       " 'helmet',\n",
       " 'shamir',\n",
       " 'progetto',\n",
       " 'reso',\n",
       " 'gish',\n",
       " 'dehdyrogenas',\n",
       " 'bayesienn',\n",
       " 'diachron',\n",
       " 'namic',\n",
       " 'contralater',\n",
       " 'kyoto',\n",
       " 'receivedatahead',\n",
       " 'eucaryot',\n",
       " 'presumpt',\n",
       " 'tuner',\n",
       " 'arrington',\n",
       " 'perspicu',\n",
       " 'varshamov',\n",
       " 'acknosoft',\n",
       " 'raatz',\n",
       " 'stalem',\n",
       " 'verticesg',\n",
       " 'ayacucho',\n",
       " 'ain',\n",
       " 'papera',\n",
       " 'inventori',\n",
       " 'livr',\n",
       " 'weyrich',\n",
       " 'viral',\n",
       " 'clearest',\n",
       " 'carbot',\n",
       " 'bucher',\n",
       " 'sfinx',\n",
       " 'gallagh',\n",
       " 'setofboundari',\n",
       " 'ehrenpreisi',\n",
       " 'prfp',\n",
       " 'matic',\n",
       " 'stampfli',\n",
       " 'vanderbilt',\n",
       " 'bobko',\n",
       " 'bachrach',\n",
       " 'audibl',\n",
       " 'gestaltist',\n",
       " 'mari',\n",
       " 'midget',\n",
       " 'mcore',\n",
       " 'wachtel',\n",
       " 'nf',\n",
       " 'pfip',\n",
       " 'ctd',\n",
       " 'scheel',\n",
       " 'tamburini',\n",
       " 'solidum',\n",
       " 'schnell',\n",
       " 'mbu',\n",
       " 'wip',\n",
       " 'grosz',\n",
       " 'zola',\n",
       " 'bred',\n",
       " 'manela',\n",
       " 'monterey',\n",
       " 'kanwish',\n",
       " 'rtop',\n",
       " 'stabi',\n",
       " 'universitat',\n",
       " 'zidek',\n",
       " 'rtdp',\n",
       " 'armijo',\n",
       " 'halter',\n",
       " 'nonmod',\n",
       " 'cindi',\n",
       " 'bacteriophag',\n",
       " 'malgrang',\n",
       " 'joy',\n",
       " 'interel',\n",
       " 'neisser',\n",
       " 'multiprogram',\n",
       " 'minstrel',\n",
       " 'dss',\n",
       " 'scarolina',\n",
       " 'bojan',\n",
       " 'naliti',\n",
       " 'boatload',\n",
       " 'fna',\n",
       " 'dierent',\n",
       " 'bookkeep',\n",
       " 'mieux',\n",
       " 'confman',\n",
       " 'kilobas',\n",
       " 'vigil',\n",
       " 'nsar',\n",
       " 'reglag',\n",
       " 'barland',\n",
       " 'clavier',\n",
       " 'performac',\n",
       " 'yannakaki',\n",
       " 'knive',\n",
       " 'misfir',\n",
       " 'goran',\n",
       " 'rod',\n",
       " 'scrutin',\n",
       " 'eswl',\n",
       " 'dom',\n",
       " 'bayli',\n",
       " 'mackworth',\n",
       " 'heeger',\n",
       " 'immobilis',\n",
       " 'inst',\n",
       " 'depthnonrec',\n",
       " 'tendon',\n",
       " 'conju',\n",
       " 'incongru',\n",
       " 'nigel',\n",
       " 'declarit',\n",
       " 'soma',\n",
       " 'nonnengart',\n",
       " 'haym',\n",
       " 'fritzk',\n",
       " 'lausann',\n",
       " 'cpga',\n",
       " 'pompliano',\n",
       " 'plethora',\n",
       " 'porat',\n",
       " 'vq',\n",
       " 'ys',\n",
       " 'propriet',\n",
       " 'wan',\n",
       " 'existenti',\n",
       " 'steinbuch',\n",
       " 'pengi',\n",
       " 'pachowicz',\n",
       " 'sched',\n",
       " 'vere',\n",
       " 'gbb',\n",
       " 'kgrftisrndskntlflqmdslrpedtgvyfcardgghgfcssascfgpdywgqgtpvtvss',\n",
       " 'unica',\n",
       " 'inplic',\n",
       " 'markram',\n",
       " 'szmidt',\n",
       " 'semiglob',\n",
       " 'referencesfix',\n",
       " 'abramowitz',\n",
       " 'nom',\n",
       " 'tiepoint',\n",
       " 'cataglyphi',\n",
       " 'tarjan',\n",
       " 'hofstadt',\n",
       " 'acjd',\n",
       " 'boden',\n",
       " 'wolfram',\n",
       " 'fnextstateg',\n",
       " 'cecconi',\n",
       " 'ammunit',\n",
       " 'migrain',\n",
       " 'iris',\n",
       " 'pheno',\n",
       " 'simil',\n",
       " 'dexter',\n",
       " 'jac',\n",
       " 'hector',\n",
       " 'nonincreas',\n",
       " 'biehl',\n",
       " 'valenc',\n",
       " 'khargonekar',\n",
       " 'katch',\n",
       " 'cu',\n",
       " 'schroeder',\n",
       " 'gcw',\n",
       " 'harp',\n",
       " 'wild',\n",
       " 'huygen',\n",
       " 'pierr',\n",
       " 'deepli',\n",
       " 'redundantli',\n",
       " 'frailti',\n",
       " 'messi',\n",
       " 'tower',\n",
       " 'schervish',\n",
       " 'tread',\n",
       " 'mhaskar',\n",
       " 'rtl',\n",
       " 'simic',\n",
       " 'floreano',\n",
       " 'accumben',\n",
       " 'daunt',\n",
       " 'poe',\n",
       " 'dictor',\n",
       " 'drome',\n",
       " 'fumig',\n",
       " 'carlson',\n",
       " 'sheather',\n",
       " 'judson',\n",
       " 'lucier',\n",
       " 'tukey',\n",
       " 'darwich',\n",
       " 'kterm',\n",
       " 'knick',\n",
       " 'shunt',\n",
       " 'kazla',\n",
       " 'maint',\n",
       " 'trophi',\n",
       " 'nakayama',\n",
       " 'gallier',\n",
       " 'suffi',\n",
       " 'bene',\n",
       " 'pierc',\n",
       " 'purg',\n",
       " 'violenc',\n",
       " 'chandler',\n",
       " 'rdr',\n",
       " 'neilson',\n",
       " 'feinstein',\n",
       " 'nimp',\n",
       " 'rac',\n",
       " 'nit',\n",
       " 'hildreth',\n",
       " 'floppi',\n",
       " 'iostyledef',\n",
       " 'pauker',\n",
       " 'nonconcav',\n",
       " 'basecal',\n",
       " 'kwown',\n",
       " 'kic',\n",
       " 'lerdahl',\n",
       " 'heurikon',\n",
       " 'kull',\n",
       " 'ension',\n",
       " 'illu',\n",
       " 'konen',\n",
       " 'wei',\n",
       " 'dup',\n",
       " 'narrowest',\n",
       " 'uspenski',\n",
       " 'semialgebra',\n",
       " 'daffi',\n",
       " 'rouseeuw',\n",
       " 'rand',\n",
       " 'prism',\n",
       " 'scopolomin',\n",
       " 'ebnn',\n",
       " 'prais',\n",
       " 'falsifi',\n",
       " 'delphi',\n",
       " 'mda',\n",
       " 'ibrahim',\n",
       " 'ibq',\n",
       " 'edgen',\n",
       " 'nrmse',\n",
       " 'mcr',\n",
       " 'messlen',\n",
       " 'unfavor',\n",
       " 'gripper',\n",
       " 'inaccuraci',\n",
       " 'goddard',\n",
       " 'dem',\n",
       " 'prec',\n",
       " 'antiparallel',\n",
       " 'predominant',\n",
       " 'melcep',\n",
       " 'lti',\n",
       " 'pronoun',\n",
       " 'yx',\n",
       " 'courtier',\n",
       " 'differentiel',\n",
       " 'carriag',\n",
       " 'atick',\n",
       " 'hagit',\n",
       " 'aeronaut',\n",
       " 'gifi',\n",
       " 'microclassifi',\n",
       " 'stateg',\n",
       " 'rjx',\n",
       " 'uncon',\n",
       " 'vraissembl',\n",
       " 'cdf',\n",
       " 'perblock',\n",
       " 'hlog',\n",
       " 'lil',\n",
       " 'receipt',\n",
       " 'wernick',\n",
       " 'polk',\n",
       " 'britton',\n",
       " 'joilrecov',\n",
       " 'intcon',\n",
       " 'tesfats',\n",
       " 'basedsystem',\n",
       " 'gurvit',\n",
       " 'anger',\n",
       " 'georgia',\n",
       " 'ccbr',\n",
       " 'lewontin',\n",
       " 'serum',\n",
       " 'nan',\n",
       " 'skovd',\n",
       " 'zzg',\n",
       " 'quotient',\n",
       " 'gelatt',\n",
       " 'stanc',\n",
       " 'rachlin',\n",
       " 'metast',\n",
       " 'benzi',\n",
       " 'hieararchi',\n",
       " 'senthilselvan',\n",
       " 'jussieu',\n",
       " 'naughton',\n",
       " 'minior',\n",
       " 'zell',\n",
       " 'lor',\n",
       " 'diagonalis',\n",
       " 'snrna',\n",
       " 'omlin',\n",
       " 'unop',\n",
       " 'rastigin',\n",
       " 'nech',\n",
       " 'dunford',\n",
       " 'hoftstadt',\n",
       " 'stiff',\n",
       " 'fvu',\n",
       " 'inlt',\n",
       " 'yardstick',\n",
       " 'lodg',\n",
       " 'contextsensit',\n",
       " 'lexicograph',\n",
       " 'hm',\n",
       " 'counterbal',\n",
       " 'dk',\n",
       " 'bplearn',\n",
       " 'reschberg',\n",
       " 'statistiqu',\n",
       " 'unpen',\n",
       " 'underwood',\n",
       " 'circumplex',\n",
       " 'bonar',\n",
       " 'aveff',\n",
       " 'thymidi',\n",
       " 'contend',\n",
       " 'preparata',\n",
       " 'dickerson',\n",
       " 'philippsen',\n",
       " 'bdev',\n",
       " 'pugh',\n",
       " 'larc',\n",
       " 'conscienc',\n",
       " 'ship',\n",
       " 'pri',\n",
       " 'spase',\n",
       " 'erform',\n",
       " 'dudchenko',\n",
       " 'guanin',\n",
       " 'demandai',\n",
       " 'vya',\n",
       " 'kurtz',\n",
       " 'kael',\n",
       " 'tramolecular',\n",
       " 'jssp',\n",
       " 'repons',\n",
       " 'bube',\n",
       " 'crane',\n",
       " 'bona',\n",
       " 'olap',\n",
       " 'eckmil',\n",
       " 'schimert',\n",
       " 'kchen',\n",
       " 'conrad',\n",
       " 'bh',\n",
       " 'uniclass',\n",
       " 'invis',\n",
       " 'sil',\n",
       " 'somatosensor',\n",
       " 'numlink',\n",
       " 'derror',\n",
       " 'sky',\n",
       " 'shapir',\n",
       " 'diet',\n",
       " 'bench',\n",
       " 'felsenstein',\n",
       " 'dietari',\n",
       " 'kole',\n",
       " 'jjffi',\n",
       " 'opi',\n",
       " 'strm',\n",
       " 'hexagon',\n",
       " 'superstructur',\n",
       " 'lego',\n",
       " 'rs',\n",
       " 'viru',\n",
       " 'licens',\n",
       " 'cornern',\n",
       " 'otto',\n",
       " 'fritz',\n",
       " 'layoutproblem',\n",
       " 'kittler',\n",
       " 'ienn',\n",
       " 'winnow',\n",
       " 'nyi',\n",
       " 'douglass',\n",
       " 'ving',\n",
       " 'xjt',\n",
       " 'progressiv',\n",
       " 'amef',\n",
       " 'renew',\n",
       " 'roget',\n",
       " 'goldreich',\n",
       " 'blockabl',\n",
       " 'confluenc',\n",
       " 'conclu',\n",
       " 'jjo',\n",
       " 'imbed',\n",
       " 'geoffrey',\n",
       " 'sch',\n",
       " 'lln',\n",
       " 'persever',\n",
       " 'elderli',\n",
       " 'preflow',\n",
       " 'amend',\n",
       " 'retail',\n",
       " 'forschungsgemein',\n",
       " 'crustacean',\n",
       " 'durbin',\n",
       " 'snlp',\n",
       " 'linesearch',\n",
       " 'underlin',\n",
       " 'cronin',\n",
       " 'knowledgetron',\n",
       " 'dissip',\n",
       " 'riemann',\n",
       " 'nonproposit',\n",
       " 'kececioglu',\n",
       " 'torranc',\n",
       " 'mint',\n",
       " 'lineg',\n",
       " 'kuperstein',\n",
       " 'gestur',\n",
       " 'traitent',\n",
       " 'trelli',\n",
       " 'reperameter',\n",
       " 'ere',\n",
       " 'christian',\n",
       " 'diggl',\n",
       " 'infarct',\n",
       " 'liminari',\n",
       " 'saitou',\n",
       " 'matriloc',\n",
       " 'ucsc',\n",
       " 'radii',\n",
       " 'tialli',\n",
       " 'powerbook',\n",
       " 'terval',\n",
       " 'lowri',\n",
       " 'steinberg',\n",
       " 'atthi',\n",
       " 'shark',\n",
       " 'andreassen',\n",
       " 'neurogen',\n",
       " 'noda',\n",
       " 'compu',\n",
       " 'nipul',\n",
       " 'gcg',\n",
       " 'javornik',\n",
       " 'rouveirol',\n",
       " 'empli',\n",
       " 'kuc',\n",
       " 'avrim',\n",
       " 'lvf',\n",
       " 'sociat',\n",
       " 'stoutchinin',\n",
       " 'schmitt',\n",
       " 'eigenmatric',\n",
       " 'psa',\n",
       " 'krzanowski',\n",
       " 'benoit',\n",
       " 'brunswick',\n",
       " 'sillier',\n",
       " 'bcsr',\n",
       " 'tnik',\n",
       " 'aviv',\n",
       " 'pailleux',\n",
       " 'fillmor',\n",
       " 'offens',\n",
       " 'cmm',\n",
       " 'bryk',\n",
       " 'unfairli',\n",
       " 'extrastriat',\n",
       " 'toernooiveld',\n",
       " 'pelleti',\n",
       " 'messr',\n",
       " 'tron',\n",
       " 'regularis',\n",
       " 'unassign',\n",
       " 'prognos',\n",
       " 'dodier',\n",
       " 'xc',\n",
       " 'acquaint',\n",
       " 'allemang',\n",
       " 'gttm',\n",
       " 'aloimono',\n",
       " 'flo',\n",
       " 'typedef',\n",
       " 'jcj',\n",
       " 'austrian',\n",
       " 'photographi',\n",
       " 'kwek',\n",
       " 'subcort',\n",
       " 'taneous',\n",
       " 'bogi',\n",
       " 'arbor',\n",
       " 'marcinkowski',\n",
       " 'repect',\n",
       " 'supertask',\n",
       " 'nondegeneraci',\n",
       " 'caseconsist',\n",
       " 'schole',\n",
       " 'cga',\n",
       " 'ufgpr',\n",
       " 'bead',\n",
       " 'smell',\n",
       " 'multipro',\n",
       " 'tw',\n",
       " 'zenio',\n",
       " 'effec',\n",
       " 'connected',\n",
       " 'fanni',\n",
       " 'daimler',\n",
       " 'artstar',\n",
       " 'crd',\n",
       " 'renato',\n",
       " 'altman',\n",
       " 'serafin',\n",
       " 'zuckerman',\n",
       " 'modulatori',\n",
       " 'babcock',\n",
       " 'paula',\n",
       " 'kerrigan',\n",
       " 'brockwel',\n",
       " 'permet',\n",
       " 'axor',\n",
       " 'missionlab',\n",
       " 'ffit',\n",
       " 'stimu',\n",
       " 'utilit',\n",
       " 'deontic',\n",
       " 'slug',\n",
       " 'pittsburgh',\n",
       " 'sl',\n",
       " 'posi',\n",
       " 'kawato',\n",
       " 'ame',\n",
       " 'lambda',\n",
       " 'acbarr',\n",
       " 'lukashin',\n",
       " 'fop',\n",
       " 'madhu',\n",
       " 'rijsbergen',\n",
       " 'ukrainec',\n",
       " 'verhzwstat',\n",
       " 'pomerleau',\n",
       " 'riccardo',\n",
       " 'nhu',\n",
       " 'nombreus',\n",
       " 'claveri',\n",
       " ...}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_min.stop_words_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(204, 'size'),\n",
       " (203, 'studi'),\n",
       " (202, 'crossov'),\n",
       " (202, 'point'),\n",
       " (201, 'evalu'),\n",
       " (201, 'experi'),\n",
       " (199, 'techniqu'),\n",
       " (198, 'form'),\n",
       " (197, 'evolv'),\n",
       " (197, 'mani'),\n",
       " (196, 'complex'),\n",
       " (196, 'evolut'),\n",
       " (196, 'space'),\n",
       " (193, 'evolutionari'),\n",
       " (191, 'learn'),\n",
       " (191, 'model'),\n",
       " (189, 'solv'),\n",
       " (188, 'order'),\n",
       " (188, 'best'),\n",
       " (188, 'section')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_token_frequency(texts,'Genetic_Algorithms',class_ids,range=(40,60),method='df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process approach: remove low-frequency tokens&non-informative tokens</br>\n",
    "1. remove tokens whose doc frequency is below x.\n",
    "2. remove tokens which occur frequently in all the seven classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tokens=[]\n",
    "for text_class in set(labels):\n",
    "    top_tokens.append(set([j for i,j in get_token_frequency(texts,text_class,class_ids,(0,50),method='absolute')]))\n",
    "overlap=set.intersection(*top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm',\n",
       " 'approach',\n",
       " 'base',\n",
       " 'differ',\n",
       " 'exampl',\n",
       " 'function',\n",
       " 'gener',\n",
       " 'learn',\n",
       " 'method',\n",
       " 'model',\n",
       " 'problem',\n",
       " 'result',\n",
       " 'set',\n",
       " 'use'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=list(stop_words_default)+list(overlap),min_df=0.005)\n",
    "X = vectorizer.fit_transform(texts).toarray() \n",
    "tokens=vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 3876)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaai',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abbrevi',\n",
       " 'abduct',\n",
       " 'abe',\n",
       " 'abil',\n",
       " 'abl',\n",
       " 'absenc',\n",
       " 'absent',\n",
       " 'absolut',\n",
       " 'absorb',\n",
       " 'abstract',\n",
       " 'abund',\n",
       " 'ac',\n",
       " 'acceler',\n",
       " 'accept',\n",
       " 'acceptor',\n",
       " 'access',\n",
       " 'accommod',\n",
       " 'accompani',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'accordingli',\n",
       " 'account',\n",
       " 'accumul',\n",
       " 'accur',\n",
       " 'accuraci',\n",
       " 'achiev',\n",
       " 'acid',\n",
       " 'ackley',\n",
       " 'acknowledg',\n",
       " 'acm',\n",
       " 'acoust',\n",
       " 'acquir',\n",
       " 'acquisit',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actuat',\n",
       " 'acut',\n",
       " 'acycl',\n",
       " 'ad',\n",
       " 'adaboost',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adequ',\n",
       " 'adf',\n",
       " 'adjac',\n",
       " 'adjust',\n",
       " 'admiss',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'advers',\n",
       " 'adversari',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'advoc',\n",
       " 'affect',\n",
       " 'affer',\n",
       " 'affin',\n",
       " 'afford',\n",
       " 'afosr',\n",
       " 'afterward',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'agenc',\n",
       " 'agent',\n",
       " 'aggreg',\n",
       " 'aggress',\n",
       " 'agnost',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aic',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'airplan',\n",
       " 'akaik',\n",
       " 'akin',\n",
       " 'al',\n",
       " 'alarm',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'algebra',\n",
       " 'algo',\n",
       " 'alias',\n",
       " 'align',\n",
       " 'allel',\n",
       " 'allen',\n",
       " 'allevi',\n",
       " 'alli',\n",
       " 'alloc',\n",
       " 'allow',\n",
       " 'alon',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alreadi',\n",
       " 'alter',\n",
       " 'altern',\n",
       " 'altogeth',\n",
       " 'alway',\n",
       " 'amari',\n",
       " 'ambigu',\n",
       " 'amen',\n",
       " 'american',\n",
       " 'amino',\n",
       " 'amplifi',\n",
       " 'amplitud',\n",
       " 'analog',\n",
       " 'analogu',\n",
       " 'analys',\n",
       " 'analysi',\n",
       " 'analyst',\n",
       " 'analyt',\n",
       " 'analyz',\n",
       " 'anatom',\n",
       " 'anc',\n",
       " 'ancestor',\n",
       " 'anderson',\n",
       " 'andrew',\n",
       " 'angelin',\n",
       " 'angl',\n",
       " 'angluin',\n",
       " 'angular',\n",
       " 'anim',\n",
       " 'animat',\n",
       " 'ann',\n",
       " 'anneal',\n",
       " 'annot',\n",
       " 'annual',\n",
       " 'anomal',\n",
       " 'anomali',\n",
       " 'anonym',\n",
       " 'anoth',\n",
       " 'anova',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'anteced',\n",
       " 'anti',\n",
       " 'anticip',\n",
       " 'anyth',\n",
       " 'anytim',\n",
       " 'anywher',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'aperiod',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'append',\n",
       " 'appendix',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appreci',\n",
       " 'appropri',\n",
       " 'approx',\n",
       " 'approxi',\n",
       " 'approxim',\n",
       " 'april',\n",
       " 'aq',\n",
       " 'aqua',\n",
       " 'ar',\n",
       " 'arbitrari',\n",
       " 'arbitrarili',\n",
       " 'arc',\n",
       " 'arch',\n",
       " 'architectur',\n",
       " 'area',\n",
       " 'arg',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'ari',\n",
       " 'aris',\n",
       " 'arithmet',\n",
       " 'ariti',\n",
       " 'arm',\n",
       " 'aros',\n",
       " 'arrang',\n",
       " 'array',\n",
       " 'arriv',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'articl',\n",
       " 'articul',\n",
       " 'artifact',\n",
       " 'artifici',\n",
       " 'asc',\n",
       " 'ascent',\n",
       " 'asexu',\n",
       " 'asid',\n",
       " 'ask',\n",
       " 'asoc',\n",
       " 'aspect',\n",
       " 'assembl',\n",
       " 'assert',\n",
       " 'assess',\n",
       " 'assign',\n",
       " 'assimil',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'assum',\n",
       " 'assumpt',\n",
       " 'assur',\n",
       " 'asymmetr',\n",
       " 'asymmetri',\n",
       " 'asymptot',\n",
       " 'asynchron',\n",
       " 'ate',\n",
       " 'atkeson',\n",
       " 'atom',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attain',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attract',\n",
       " 'attractor',\n",
       " 'attribut',\n",
       " 'au',\n",
       " 'auditori',\n",
       " 'auer',\n",
       " 'augment',\n",
       " 'august',\n",
       " 'author',\n",
       " 'auto',\n",
       " 'autoclass',\n",
       " 'autocorrel',\n",
       " 'autom',\n",
       " 'automat',\n",
       " 'automata',\n",
       " 'automaton',\n",
       " 'autonom',\n",
       " 'autoregress',\n",
       " 'auxiliari',\n",
       " 'avail',\n",
       " 'avenu',\n",
       " 'averag',\n",
       " 'avoid',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'ax',\n",
       " 'axe',\n",
       " 'axi',\n",
       " 'axiom',\n",
       " 'axiomat',\n",
       " 'axon',\n",
       " 'ba',\n",
       " 'backgammon',\n",
       " 'background',\n",
       " 'backprop',\n",
       " 'backpropag',\n",
       " 'backtrack',\n",
       " 'backup',\n",
       " 'backward',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badli',\n",
       " 'bag',\n",
       " 'baird',\n",
       " 'baker',\n",
       " 'bakiri',\n",
       " 'balanc',\n",
       " 'ball',\n",
       " 'ballard',\n",
       " 'band',\n",
       " 'bandwidth',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'bare',\n",
       " 'bareiss',\n",
       " 'barlow',\n",
       " 'barrier',\n",
       " 'barron',\n",
       " 'bartlett',\n",
       " 'barto',\n",
       " 'baselin',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'basin',\n",
       " 'batch',\n",
       " 'baum',\n",
       " 'bay',\n",
       " 'bayesian',\n",
       " 'bc',\n",
       " 'bcm',\n",
       " 'beam',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'becam',\n",
       " 'becker',\n",
       " 'becom',\n",
       " 'bed',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'begun',\n",
       " 'behav',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'belew',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'bell',\n",
       " 'bellman',\n",
       " 'belong',\n",
       " 'benchmark',\n",
       " 'benefici',\n",
       " 'benefit',\n",
       " 'benign',\n",
       " 'bennett',\n",
       " 'berg',\n",
       " 'bergadano',\n",
       " 'berger',\n",
       " 'berkeley',\n",
       " 'bernardo',\n",
       " 'bernoulli',\n",
       " 'bertseka',\n",
       " 'besag',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'beta',\n",
       " 'better',\n",
       " 'bg',\n",
       " 'bi',\n",
       " 'bia',\n",
       " 'bianchi',\n",
       " 'bias',\n",
       " 'bibliographi',\n",
       " 'bic',\n",
       " 'bidirect',\n",
       " 'bienenstock',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'bilinear',\n",
       " 'bimod',\n",
       " 'bin',\n",
       " 'binari',\n",
       " 'bind',\n",
       " 'binomi',\n",
       " 'biolog',\n",
       " 'biologist',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'bishop',\n",
       " 'bit',\n",
       " 'black',\n",
       " 'blame',\n",
       " 'blend',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'blood',\n",
       " 'blue',\n",
       " 'blum',\n",
       " 'blumer',\n",
       " 'blur',\n",
       " 'bn',\n",
       " 'board',\n",
       " 'bodi',\n",
       " 'boltzmann',\n",
       " 'bond',\n",
       " 'book',\n",
       " 'booker',\n",
       " 'boolean',\n",
       " 'boost',\n",
       " 'bootstrap',\n",
       " 'border',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'bottleneck',\n",
       " 'bound',\n",
       " 'boundari',\n",
       " 'boutili',\n",
       " 'box',\n",
       " 'bp',\n",
       " 'bracket',\n",
       " 'bradtk',\n",
       " 'brain',\n",
       " 'branch',\n",
       " 'bratko',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breast',\n",
       " 'breed',\n",
       " 'breiman',\n",
       " 'breviti',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'briefli',\n",
       " 'brigad',\n",
       " 'bright',\n",
       " 'bring',\n",
       " 'broad',\n",
       " 'broadcast',\n",
       " 'broader',\n",
       " 'broadli',\n",
       " 'brodley',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brunk',\n",
       " 'brute',\n",
       " 'bs',\n",
       " 'bu',\n",
       " 'buchanan',\n",
       " 'bucket',\n",
       " 'buffer',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'builder',\n",
       " 'built',\n",
       " 'bulk',\n",
       " 'buntin',\n",
       " 'burden',\n",
       " 'busi',\n",
       " 'buy',\n",
       " 'bw',\n",
       " 'ca',\n",
       " 'cabelli',\n",
       " 'cach',\n",
       " 'calcul',\n",
       " 'calculu',\n",
       " 'calibr',\n",
       " 'california',\n",
       " 'cambridg',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'canada',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candid',\n",
       " 'canon',\n",
       " 'capabl',\n",
       " 'capac',\n",
       " 'capit',\n",
       " 'captur',\n",
       " 'car',\n",
       " 'carbonel',\n",
       " 'card',\n",
       " 'cardi',\n",
       " 'cardin',\n",
       " 'care',\n",
       " 'carlo',\n",
       " 'carnegi',\n",
       " 'carpent',\n",
       " 'carri',\n",
       " 'cart',\n",
       " 'cartesian',\n",
       " 'caruana',\n",
       " 'cascad',\n",
       " 'case',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'catastroph',\n",
       " 'categor',\n",
       " 'categori',\n",
       " 'caus',\n",
       " 'causal',\n",
       " 'causat',\n",
       " 'cb',\n",
       " 'cbr',\n",
       " 'cc',\n",
       " 'ccr',\n",
       " 'ceas',\n",
       " 'cell',\n",
       " 'cellular',\n",
       " 'censor',\n",
       " 'center',\n",
       " 'centr',\n",
       " 'central',\n",
       " 'centuri',\n",
       " 'certain',\n",
       " 'certainli',\n",
       " 'certainti',\n",
       " 'cesa',\n",
       " 'cestnik',\n",
       " 'cf',\n",
       " 'cg',\n",
       " 'chain',\n",
       " 'challeng',\n",
       " 'chan',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'channel',\n",
       " 'chao',\n",
       " 'chaotic',\n",
       " 'chapman',\n",
       " 'chapter',\n",
       " 'charact',\n",
       " 'character',\n",
       " 'characteris',\n",
       " 'characterist',\n",
       " 'charg',\n",
       " 'chase',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'check',\n",
       " 'checker',\n",
       " 'cheeseman',\n",
       " 'chef',\n",
       " 'chemic',\n",
       " 'chen',\n",
       " 'cheng',\n",
       " 'chernoff',\n",
       " 'chervonenki',\n",
       " 'chess',\n",
       " 'chi',\n",
       " 'child',\n",
       " 'children',\n",
       " 'chip',\n",
       " 'choic',\n",
       " 'chomski',\n",
       " 'choos',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chromosom',\n",
       " 'chunk',\n",
       " 'ci',\n",
       " 'circl',\n",
       " 'circuit',\n",
       " 'circular',\n",
       " 'circumst',\n",
       " 'circumv',\n",
       " 'cite',\n",
       " 'citi',\n",
       " 'citr',\n",
       " 'cl',\n",
       " 'claim',\n",
       " 'clarifi',\n",
       " 'clariti',\n",
       " 'clark',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classif',\n",
       " 'classifi',\n",
       " 'claus',\n",
       " 'clausal',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " 'clearli',\n",
       " 'cleveland',\n",
       " 'clever',\n",
       " 'cliff',\n",
       " 'climb',\n",
       " 'clinic',\n",
       " 'cliqu',\n",
       " 'clock',\n",
       " 'clone',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'closur',\n",
       " 'cloud',\n",
       " 'clue',\n",
       " 'cluster',\n",
       " 'clutter',\n",
       " 'cm',\n",
       " 'cmac',\n",
       " 'cn',\n",
       " 'cnf',\n",
       " 'coars',\n",
       " 'cobweb',\n",
       " 'code',\n",
       " 'codeword',\n",
       " 'codon',\n",
       " 'coeffici',\n",
       " 'coevolut',\n",
       " 'coevolutionari',\n",
       " 'coevolv',\n",
       " 'cognit',\n",
       " 'cohen',\n",
       " 'coher',\n",
       " 'cohn',\n",
       " 'coin',\n",
       " 'coincid',\n",
       " 'coli',\n",
       " 'collabor',\n",
       " 'collaps',\n",
       " 'colleagu',\n",
       " 'collect',\n",
       " 'colleg',\n",
       " 'collin',\n",
       " 'collis',\n",
       " 'color',\n",
       " 'column',\n",
       " 'com',\n",
       " 'combat',\n",
       " 'combin',\n",
       " 'combinatori',\n",
       " 'come',\n",
       " 'command',\n",
       " 'comment',\n",
       " 'commerci',\n",
       " 'commit',\n",
       " 'committe',\n",
       " 'common',\n",
       " 'commonli',\n",
       " 'commun',\n",
       " 'comp',\n",
       " 'compact',\n",
       " 'compactli',\n",
       " 'compani',\n",
       " 'companion',\n",
       " 'compar',\n",
       " 'comparison',\n",
       " 'compat',\n",
       " 'compel',\n",
       " 'compens',\n",
       " 'compet',\n",
       " 'competit',\n",
       " 'competitor',\n",
       " 'compil',\n",
       " 'complement',\n",
       " 'complementari',\n",
       " 'complet',\n",
       " 'complex',\n",
       " 'complianc',\n",
       " 'complic',\n",
       " 'compon',\n",
       " 'compos',\n",
       " 'composit',\n",
       " 'compound',\n",
       " 'comprehens',\n",
       " 'compress',\n",
       " 'compris',\n",
       " 'compromis',\n",
       " 'comput',\n",
       " 'concaten',\n",
       " 'concav',\n",
       " 'conceiv',\n",
       " 'concentr',\n",
       " 'concept',\n",
       " 'conceptu',\n",
       " 'concern',\n",
       " 'concis',\n",
       " 'conclud',\n",
       " 'conclus',\n",
       " 'concret',\n",
       " 'concurr',\n",
       " 'condens',\n",
       " 'condit',\n",
       " 'condition',\n",
       " 'conduct',\n",
       " 'cone',\n",
       " 'confer',\n",
       " 'confid',\n",
       " 'configur',\n",
       " 'confin',\n",
       " 'confirm',\n",
       " 'conflict',\n",
       " 'conform',\n",
       " 'confront',\n",
       " 'confus',\n",
       " 'conjectur',\n",
       " 'conjug',\n",
       " 'conjunct',\n",
       " 'connect',\n",
       " 'connection',\n",
       " 'connectionist',\n",
       " 'conquer',\n",
       " 'consecut',\n",
       " 'consensu',\n",
       " 'consequ',\n",
       " 'conserv',\n",
       " 'consid',\n",
       " 'consider',\n",
       " 'consist',\n",
       " 'constant',\n",
       " 'constantli',\n",
       " 'constitu',\n",
       " 'constitut',\n",
       " 'constrain',\n",
       " 'constraint',\n",
       " 'construct',\n",
       " 'consult',\n",
       " 'consum',\n",
       " 'consumpt',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'content',\n",
       " 'context',\n",
       " 'contextu',\n",
       " 'contigu',\n",
       " 'conting',\n",
       " 'continu',\n",
       " 'continuum',\n",
       " 'contour',\n",
       " 'contract',\n",
       " 'contradict',\n",
       " 'contradictori',\n",
       " 'contrari',\n",
       " 'contrast',\n",
       " 'contribut',\n",
       " 'control',\n",
       " 'controversi',\n",
       " 'conveni',\n",
       " 'convent',\n",
       " 'converg',\n",
       " 'convers',\n",
       " 'convert',\n",
       " 'convex',\n",
       " 'convey',\n",
       " 'convinc',\n",
       " 'convolut',\n",
       " 'cook',\n",
       " 'cool',\n",
       " 'cooper',\n",
       " 'coordin',\n",
       " 'cope',\n",
       " 'copi',\n",
       " 'copyright',\n",
       " 'core',\n",
       " 'corner',\n",
       " 'corollari',\n",
       " 'corpor',\n",
       " 'corpu',\n",
       " 'correct',\n",
       " 'correctli',\n",
       " 'correl',\n",
       " 'correspond',\n",
       " 'correspondingli',\n",
       " 'corrupt',\n",
       " 'cortex',\n",
       " 'cortic',\n",
       " 'cost',\n",
       " 'costli',\n",
       " 'count',\n",
       " 'countabl',\n",
       " 'counter',\n",
       " 'counterexampl',\n",
       " 'counterfactu',\n",
       " 'counterpart',\n",
       " 'countri',\n",
       " 'coupl',\n",
       " 'cours',\n",
       " 'covari',\n",
       " 'cover',\n",
       " 'coverag',\n",
       " 'cox',\n",
       " 'cp',\n",
       " 'cpt',\n",
       " 'cpu',\n",
       " 'craft',\n",
       " 'craven',\n",
       " 'creat',\n",
       " 'creation',\n",
       " 'creativ',\n",
       " 'creatur',\n",
       " 'credit',\n",
       " 'criteria',\n",
       " 'criterion',\n",
       " 'critic',\n",
       " 'critiqu',\n",
       " 'cross',\n",
       " 'crossov',\n",
       " 'crucial',\n",
       " 'crude',\n",
       " 'cryptograph',\n",
       " 'cs',\n",
       " 'csp',\n",
       " 'cube',\n",
       " 'cubic',\n",
       " 'cue',\n",
       " 'cultur',\n",
       " 'cumul',\n",
       " 'cun',\n",
       " 'cup',\n",
       " 'current',\n",
       " 'curs',\n",
       " 'curv',\n",
       " 'curvatur',\n",
       " 'custom',\n",
       " 'cut',\n",
       " 'cutoff',\n",
       " 'cv',\n",
       " 'cx',\n",
       " 'cycl',\n",
       " 'cyclic',\n",
       " 'da',\n",
       " 'dag',\n",
       " 'daili',\n",
       " 'damag',\n",
       " 'danger',\n",
       " 'dark',\n",
       " 'darken',\n",
       " 'darpa',\n",
       " 'darwin',\n",
       " 'darwinian',\n",
       " 'dash',\n",
       " 'data',\n",
       " 'databas',\n",
       " 'dataset',\n",
       " 'date',\n",
       " 'davi',\n",
       " 'david',\n",
       " 'dawid',\n",
       " 'day',\n",
       " 'dayan',\n",
       " 'dc',\n",
       " 'dci',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dealt',\n",
       " 'dean',\n",
       " 'death',\n",
       " 'deb',\n",
       " 'debat',\n",
       " 'dec',\n",
       " 'decad',\n",
       " 'decay',\n",
       " 'decemb',\n",
       " 'decept',\n",
       " 'decid',\n",
       " 'decim',\n",
       " 'decis',\n",
       " 'declar',\n",
       " 'declin',\n",
       " 'decod',\n",
       " 'decompos',\n",
       " 'decomposit',\n",
       " 'deconvolut',\n",
       " 'decorrel',\n",
       " 'decoupl',\n",
       " 'decreas',\n",
       " 'dedic',\n",
       " 'deduc',\n",
       " 'deduct',\n",
       " 'deem',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'def',\n",
       " 'default',\n",
       " 'defect',\n",
       " 'defens',\n",
       " 'defer',\n",
       " 'defici',\n",
       " 'defin',\n",
       " 'definit',\n",
       " 'deform',\n",
       " 'degener',\n",
       " 'degrad',\n",
       " 'degre',\n",
       " 'dejong',\n",
       " 'delay',\n",
       " 'delet',\n",
       " 'deliber',\n",
       " 'delin',\n",
       " 'deliv',\n",
       " 'delta',\n",
       " 'demand',\n",
       " 'demonstr',\n",
       " 'dempster',\n",
       " 'denomin',\n",
       " 'denot',\n",
       " 'dens',\n",
       " 'densiti',\n",
       " 'depart',\n",
       " 'departur',\n",
       " 'depend',\n",
       " 'depict',\n",
       " 'deploy',\n",
       " 'depth',\n",
       " 'der',\n",
       " 'deriv',\n",
       " 'descend',\n",
       " 'descent',\n",
       " 'describ',\n",
       " 'descript',\n",
       " 'descriptor',\n",
       " 'deserv',\n",
       " 'design',\n",
       " 'desir',\n",
       " 'despit',\n",
       " 'destin',\n",
       " 'destroy',\n",
       " 'destruct',\n",
       " 'det',\n",
       " 'detect',\n",
       " 'detector',\n",
       " 'deterior',\n",
       " 'determin',\n",
       " 'determinist',\n",
       " 'detriment',\n",
       " 'develop',\n",
       " 'development',\n",
       " 'deviat',\n",
       " 'devic',\n",
       " 'devis',\n",
       " 'devot',\n",
       " 'df',\n",
       " 'dfa',\n",
       " 'di',\n",
       " 'diabet',\n",
       " 'diagnos',\n",
       " 'diagnosi',\n",
       " 'diagnost',\n",
       " 'diagon',\n",
       " 'diagram',\n",
       " 'diamet',\n",
       " 'dichotomi',\n",
       " 'dictat',\n",
       " 'dictionari',\n",
       " 'die',\n",
       " 'dietterich',\n",
       " 'differenti',\n",
       " 'difficult',\n",
       " 'difficulti',\n",
       " 'diffus',\n",
       " 'digit',\n",
       " 'dilemma',\n",
       " 'dim',\n",
       " 'dimac',\n",
       " 'dimens',\n",
       " 'dimension',\n",
       " 'diminish',\n",
       " 'direct',\n",
       " 'directli',\n",
       " 'dirichlet',\n",
       " 'disabl',\n",
       " 'disadvantag',\n",
       " 'disagr',\n",
       " 'disagre',\n",
       " 'disambigu',\n",
       " 'disappear',\n",
       " 'discard',\n",
       " 'discern',\n",
       " 'disciplin',\n",
       " 'discontinu',\n",
       " 'discount',\n",
       " 'discourag',\n",
       " 'discours',\n",
       " 'discov',\n",
       " 'discoveri',\n",
       " 'discrep',\n",
       " 'discret',\n",
       " 'discrimin',\n",
       " 'discuss',\n",
       " 'diseas',\n",
       " 'disjoint',\n",
       " 'disjunct',\n",
       " 'disk',\n",
       " 'disord',\n",
       " 'dispar',\n",
       " 'dispatch',\n",
       " 'dispers',\n",
       " 'displac',\n",
       " 'display',\n",
       " 'disregard',\n",
       " 'disrupt',\n",
       " 'dissert',\n",
       " 'dissimilar',\n",
       " 'distanc',\n",
       " 'distant',\n",
       " 'distinct',\n",
       " 'distinguish',\n",
       " 'distort',\n",
       " 'distribut',\n",
       " 'disturb',\n",
       " 'diverg',\n",
       " 'divers',\n",
       " 'divid',\n",
       " 'divis',\n",
       " 'dl',\n",
       " 'dm',\n",
       " 'dna',\n",
       " 'dnf',\n",
       " 'document',\n",
       " 'dog',\n",
       " 'domain',\n",
       " 'domin',\n",
       " 'domingo',\n",
       " 'donor',\n",
       " 'door',\n",
       " 'dorigo',\n",
       " 'dot',\n",
       " 'doubl',\n",
       " 'doubt',\n",
       " 'doyl',\n",
       " 'dozen',\n",
       " 'dp',\n",
       " 'dr',\n",
       " 'draft',\n",
       " 'dramat',\n",
       " 'drastic',\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data/Cora_enrich/BOW_texts_3876.txt',X,fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Cora_enrich/tokens_3876.pickle','wb') as f:\n",
    "    pickle.dump(tokens, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate subgraphs from the original network, according to labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.read_adjlist('data/Cora_enrich/idx_adjlist.txt',nodetype=int,create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "with open('data/Cora_enrich/labels.txt') as f:\n",
    "    for line in f:\n",
    "        labels.append(line.strip())\n",
    "labels=np.array(labels)\n",
    "\n",
    "with open('data/Cora_enrich/tokens_3876.pickle','rb') as f:\n",
    "    tokens=pickle.load(f)\n",
    "tokens=np.array(tokens)\n",
    "\n",
    "texts=np.loadtxt('data/Cora_enrich/BOW_texts_3876.txt',dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Case_Based',\n",
       " 'Genetic_Algorithms',\n",
       " 'Neural_Networks',\n",
       " 'Probabilistic_Methods',\n",
       " 'Reinforcement_Learning',\n",
       " 'Rule_Learning',\n",
       " 'Theory'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Neural_Networks','Probabilistic_Methods','Theory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_input(classes,G,labels,texts):\n",
    "    '''\n",
    "    args:\n",
    "    classes: list of strs\n",
    "    G: original graph (DiGraph)\n",
    "    labels: original labels\n",
    "    texts: original BOW texts\n",
    "    \n",
    "    return:\n",
    "    G_sub_idx: subgraph from G containing nodes in the specified classes and edges between them. \n",
    "        Isolates are removed.\n",
    "    labels_sub: labels consistent with G_sub_idx\n",
    "    texts_sub: BOW texts consistent with G_sub_idx \n",
    "    sub_idx_dict: the map of (original idx: new_idx) \n",
    "    '''\n",
    "    sub_idx_list=[]\n",
    "    for i,l in enumerate(labels):\n",
    "        if l in classes:\n",
    "            sub_idx_list.append(i)\n",
    "            \n",
    "    G_sub=nx.DiGraph(nx.subgraph(G,sub_idx_list)) \n",
    "    G_sub.remove_nodes_from(list(nx.isolates(G_sub)))\n",
    "    \n",
    "    sub_idx_dict={v:k for k,v in enumerate(list(G_sub.nodes))}\n",
    "    sub_idx_list=list(sub_idx_dict.keys())\n",
    "    \n",
    "    G_sub_idx=nx.DiGraph()\n",
    "    edges=[(sub_idx_dict[i],sub_idx_dict[j]) for i,j in G_sub.edges]\n",
    "    G_sub_idx.add_edges_from(edges)\n",
    "    \n",
    "    labels_sub=labels[sub_idx_list]\n",
    "    texts_sub=texts[sub_idx_list] \n",
    "    \n",
    "    return G_sub_idx,labels_sub,texts_sub,sub_idx_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
